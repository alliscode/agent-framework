# Copyright (c) Microsoft. All rights reserved.

"""Compaction strategies for context management.

Strategies are applied in order from least to most aggressive:
1. Clear - Replace tool results with placeholders (respecting durability)
2. Externalize - Write large content to storage, keep pointer + summary (full content preserved)
3. Summarize - LLM-compress older spans into structured summaries (original lost)
4. Drop - Remove from prompt entirely (last resort)

See CONTEXT_COMPACTION_DESIGN.md for full architecture details.
"""

from __future__ import annotations

import logging
import uuid
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import TYPE_CHECKING, Any, Protocol

from ._durability import (
    DEFAULT_DURABILITY_POLICIES,
    ToolDurability,
    ToolDurabilityPolicy,
    ToolResultEnvelope,
)
from ._summary import ArtifactReference, StructuredSummary
from ._types import (
    ClearRecord,
    CompactionPlan,
    DropRecord,
    ExternalizationRecord,
    SpanReference,
    SummarizationRecord,
)

if TYPE_CHECKING:
    from ..._threads import AgentThread
    from ..._types import ChatMessage
    from ._store import ArtifactStore
    from ._tokenizer import ProviderAwareTokenizer, TokenBudget
    from ._turn_context import TurnContext

logger = logging.getLogger(__name__)


def _count_message_tokens(msg: ChatMessage, tokenizer: ProviderAwareTokenizer) -> int:
    """Count tokens for a message including all content types.

    Unlike ``msg.text`` which only returns TextContent, this counts tokens
    from FunctionCallContent (name + arguments) and FunctionResultContent
    (result) as well — matching how the API counts tokens.
    """
    from ..._types import FunctionCallContent, FunctionResultContent, TextContent

    total = 0
    contents = getattr(msg, "contents", None)
    if not contents:
        # Fallback to msg.text for simple messages
        text = getattr(msg, "text", None) or ""
        return tokenizer.count_tokens(str(text))

    for content in contents:
        if isinstance(content, TextContent):
            total += tokenizer.count_tokens(content.text or "")
        elif isinstance(content, FunctionCallContent):
            total += tokenizer.count_tokens(content.name or "")
            args = content.arguments
            if isinstance(args, dict):
                import json

                args = json.dumps(args)
            total += tokenizer.count_tokens(str(args or ""))
        elif isinstance(content, FunctionResultContent):
            total += tokenizer.count_tokens(str(content.result or ""))
        else:
            total += tokenizer.count_tokens(str(content))
    return total


@dataclass
class CompactionProposal:
    """A proposed compaction action.

    Proposals are generated by strategies during analysis and then
    executed if approved.

    Attributes:
        strategy: Name of the strategy proposing this.
        span: The span of messages to compact.
        estimated_tokens_freed: Estimated tokens freed by this compaction.
        reason: Human-readable explanation of why this was proposed.
        priority: Lower is higher priority (applied first).
        metadata: Strategy-specific metadata.
    """

    strategy: str
    span: SpanReference
    estimated_tokens_freed: int
    reason: str
    priority: int = 0
    metadata: dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "strategy": self.strategy,
            "span": self.span.to_dict(),
            "estimated_tokens_freed": self.estimated_tokens_freed,
            "reason": self.reason,
            "priority": self.priority,
            "metadata": self.metadata,
        }


class Summarizer(Protocol):
    """Protocol for LLM-based summarization.

    Implementations should use a cheaper/faster model for summarization
    to avoid impacting the main conversation budget.
    """

    async def summarize(
        self,
        messages: list[ChatMessage],
        *,
        target_token_ratio: float = 0.25,
        preserve_facts: list[str] | None = None,
    ) -> StructuredSummary:
        """Summarize a sequence of messages into a structured summary.

        Args:
            messages: The messages to summarize.
            target_token_ratio: Target ratio of summary to original tokens.
            preserve_facts: Facts that must be preserved in summary.

        Returns:
            A StructuredSummary of the messages.
        """
        ...


class CompactionStrategy(ABC):
    """Base class for compaction strategies.

    Strategies analyze the thread and propose compactions. They are applied
    in order from least to most aggressive based on aggressiveness level.
    """

    @property
    @abstractmethod
    def name(self) -> str:
        """Strategy name for logging/observability."""
        ...

    @property
    @abstractmethod
    def aggressiveness(self) -> int:
        """Aggressiveness level (lower = less aggressive, applied first)."""
        ...

    @abstractmethod
    async def analyze(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        turn_context: TurnContext | None = None,
    ) -> list[CompactionProposal]:
        """Analyze thread and propose compactions.

        Args:
            thread: The agent thread to analyze.
            current_plan: The current compaction plan (if any).
            budget: Token budget constraints.
            tokenizer: Tokenizer for counting.
            turn_context: Turn context for loop breaking.

        Returns:
            List of proposed compactions.
        """
        ...

    @abstractmethod
    async def execute(
        self,
        proposal: CompactionProposal,
        thread: AgentThread,
        tokenizer: ProviderAwareTokenizer,
    ) -> ClearRecord | SummarizationRecord | ExternalizationRecord | DropRecord:
        """Execute a proposed compaction.

        Args:
            proposal: The proposal to execute.
            thread: The agent thread.
            tokenizer: Tokenizer for counting.

        Returns:
            Record of what was compacted.
        """
        ...


class ClearStrategy(CompactionStrategy):
    """Clear strategy - replace tool results with placeholders.

    This is the least aggressive strategy. It respects durability rules:
    - EPHEMERAL: Always clearable
    - ANCHORING: Keep key fields
    - REPLAYABLE: Check determinism before clearing
    - NON_REPLAYABLE: Do not clear (use externalize instead)
    """

    def __init__(
        self,
        *,
        policy_overrides: dict[str, ToolDurabilityPolicy] | None = None,
        min_tokens_to_clear: int = 100,
        preserve_recent_turns: int = 3,
    ):
        """Initialize the clear strategy.

        Args:
            policy_overrides: Override durability policies for specific tools.
            min_tokens_to_clear: Minimum token count before considering clearing.
            preserve_recent_turns: Don't clear results from recent turns.
        """
        self._policy_overrides = policy_overrides or {}
        self._min_tokens_to_clear = min_tokens_to_clear
        self._preserve_recent_turns = preserve_recent_turns

    @property
    def name(self) -> str:
        return "clear"

    @property
    def aggressiveness(self) -> int:
        return 1  # Least aggressive

    async def analyze(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        turn_context: TurnContext | None = None,
    ) -> list[CompactionProposal]:
        """Find clearable tool results."""
        proposals: list[CompactionProposal] = []

        if thread.message_store is None:
            return proposals

        messages = await thread.message_store.list_messages()
        if not messages:
            return proposals

        # Preserve only the last N messages by position (not by user-turn).
        # In single-user-message conversations, user-turn-based recency
        # treats ALL messages as "turn 1" and blocks all compaction.
        preserve_tail = self._preserve_recent_turns * 4  # ~4 msgs per logical turn
        clearable_end = max(0, len(messages) - preserve_tail)

        for i, msg in enumerate(messages):
            if msg.message_id is None:
                continue

            # Skip if already compacted
            if current_plan is not None:
                action, _ = current_plan.get_action(msg.message_id)
                from ._types import CompactionAction

                if action != CompactionAction.INCLUDE:
                    continue

            # Only process tool results
            if msg.role.value != "tool":
                continue

            # Check for tool result envelope in additional_properties
            envelope_data = msg.additional_properties.get("tool_result_envelope")
            if envelope_data is None:
                # Try to infer durability from tool name if no envelope
                tool_name = msg.additional_properties.get("tool_name", "unknown")
                durability = self._get_durability_for_tool(tool_name)
            else:
                envelope = ToolResultEnvelope.from_dict(envelope_data)
                durability = envelope.get_effective_durability(self._policy_overrides)
                tool_name = envelope.tool_name

            # Check if clearable based on durability
            if durability == ToolDurability.NON_REPLAYABLE:
                continue  # Don't clear, need to externalize

            # Check recency — preserve recent messages by position
            if i >= clearable_end:
                continue

            # Check token count
            token_count = _count_message_tokens(msg, tokenizer)
            if token_count < self._min_tokens_to_clear:
                continue

            # Create proposal — use message index as approximate turn
            msg_turn = len([m for m in messages[:i] if m.role.value == "user"])
            span = SpanReference(
                message_ids=[msg.message_id],
                first_turn=msg_turn,
                last_turn=msg_turn,
            )

            proposals.append(
                CompactionProposal(
                    strategy=self.name,
                    span=span,
                    estimated_tokens_freed=token_count - 20,  # Placeholder ~20 tokens
                    reason=f"Clear {durability.value} tool result: {tool_name}",
                    priority=1 if durability == ToolDurability.EPHEMERAL else 2,
                    metadata={
                        "tool_name": tool_name,
                        "durability": durability.value,
                        "original_tokens": token_count,
                    },
                ),
            )

        return proposals

    async def execute(
        self,
        proposal: CompactionProposal,
        thread: AgentThread,
        tokenizer: ProviderAwareTokenizer,
    ) -> ClearRecord:
        """Execute the clear operation."""
        # Extract preserved fields if any
        preserved_fields: dict[str, Any] = {}

        if thread.message_store is not None:
            messages = await thread.message_store.list_messages()
            for msg in messages:
                if msg.message_id in proposal.span.message_ids:
                    envelope_data = msg.additional_properties.get("tool_result_envelope")
                    if envelope_data:
                        envelope = ToolResultEnvelope.from_dict(envelope_data)
                        preserved_fields = envelope.key_fields.copy()
                        preserved_fields["tool_name"] = envelope.tool_name
                        preserved_fields["outcome"] = envelope.outcome
                    break

        return ClearRecord(
            span=proposal.span,
            preserved_fields=preserved_fields,
        )

    def _get_durability_for_tool(self, tool_name: str) -> ToolDurability:
        """Get durability for a tool by name."""
        if tool_name in self._policy_overrides:
            return self._policy_overrides[tool_name].durability
        if tool_name in DEFAULT_DURABILITY_POLICIES:
            return DEFAULT_DURABILITY_POLICIES[tool_name].durability
        return ToolDurability.ANCHORING  # Default to anchoring


class SummarizeStrategy(CompactionStrategy):
    """Summarize strategy - LLM-compress older spans.

    Uses a separate (cheaper) model to summarize conversation spans
    into structured summaries that resist drift.
    """

    def __init__(
        self,
        summarizer: Summarizer,
        *,
        target_token_ratio: float = 0.25,
        min_span_tokens: int = 500,
        min_span_messages: int = 3,
        preserve_recent_turns: int = 2,
    ):
        """Initialize the summarize strategy.

        Args:
            summarizer: The summarizer to use.
            target_token_ratio: Target ratio of summary to original.
            min_span_tokens: Minimum tokens in span before summarizing.
            min_span_messages: Minimum messages in span before summarizing.
            preserve_recent_turns: Don't summarize recent turns.
        """
        self._summarizer = summarizer
        self._target_token_ratio = target_token_ratio
        self._min_span_tokens = min_span_tokens
        self._min_span_messages = min_span_messages
        self._preserve_recent_turns = preserve_recent_turns

    @property
    def name(self) -> str:
        return "summarize"

    @property
    def aggressiveness(self) -> int:
        return 3

    async def analyze(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        turn_context: TurnContext | None = None,
    ) -> list[CompactionProposal]:
        """Find spans suitable for summarization."""
        proposals: list[CompactionProposal] = []

        # Skip if rehydration happened this turn
        if turn_context is not None and turn_context.should_skip_aggressive_compaction():
            logger.debug("Skipping summarization due to rehydration this turn")
            return proposals

        if thread.message_store is None:
            return proposals

        messages = await thread.message_store.list_messages()
        if len(messages) < self._min_span_messages:
            return proposals

        # Find conversation turns — group by assistant responses, not user messages.
        # In single-user-message conversations (common in harness), user-based
        # grouping creates only 1-2 turns making everything "recent" and unsummarizable.
        # Each assistant message (+ following tool results) forms a logical turn.
        turns: list[list[int]] = []  # List of message indices per turn
        current_turn_msgs: list[int] = []

        for i, msg in enumerate(messages):
            # Start a new turn when we see an assistant message (if we have accumulated messages)
            if msg.role.value == "assistant" and current_turn_msgs:
                turns.append(current_turn_msgs)
                current_turn_msgs = []
            current_turn_msgs.append(i)

        if current_turn_msgs:
            turns.append(current_turn_msgs)

        # Don't summarize recent turns
        summarizable_turns = turns[: -self._preserve_recent_turns] if len(turns) > self._preserve_recent_turns else []

        if not summarizable_turns:
            return proposals

        # Protect only the first user message — not the entire first turn.
        # The user's original request must survive compaction, but assistant
        # responses and tool results from early turns are fair game.
        protected_indices: set[int] = set()
        for idx in range(len(messages)):
            if messages[idx].role.value == "user":
                protected_indices.add(idx)
                break  # Only protect the FIRST user message

        # Find contiguous spans to summarize
        span_indices: list[int] = []
        span_tokens = 0
        span_first_turn = 0

        for turn_idx, turn_msg_indices in enumerate(summarizable_turns):
            # Check if any message in this turn is already compacted
            any_compacted = False
            if current_plan is not None:
                for msg_idx in turn_msg_indices:
                    msg = messages[msg_idx]
                    if msg.message_id:
                        from ._types import CompactionAction

                        action, _ = current_plan.get_action(msg.message_id)
                        if action != CompactionAction.INCLUDE:
                            any_compacted = True
                            break

            if any_compacted:
                # Create proposal for current span if big enough
                if span_tokens >= self._min_span_tokens and len(span_indices) >= self._min_span_messages:
                    proposals.append(
                        self._create_proposal(messages, span_indices, span_tokens, span_first_turn, turn_idx - 1),
                    )
                span_indices = []
                span_tokens = 0
                continue

            # Add turn to span
            if not span_indices:
                span_first_turn = turn_idx

            for msg_idx in turn_msg_indices:
                if msg_idx in protected_indices:
                    continue
                msg = messages[msg_idx]
                if msg.message_id:  # Only include messages with IDs
                    span_indices.append(msg_idx)
                    span_tokens += _count_message_tokens(msg, tokenizer)

        # Final span
        if span_tokens >= self._min_span_tokens and len(span_indices) >= self._min_span_messages:
            proposals.append(
                self._create_proposal(
                    messages, span_indices, span_tokens, span_first_turn, len(summarizable_turns) - 1
                ),
            )

        return proposals

    def _create_proposal(
        self,
        messages: list[ChatMessage],
        indices: list[int],
        tokens: int,
        first_turn: int,
        last_turn: int,
    ) -> CompactionProposal:
        """Create a summarization proposal."""
        # Filter to messages with IDs (filter out None)
        message_ids: list[str] = [msg_id for i in indices if (msg_id := messages[i].message_id) is not None]

        span = SpanReference(
            message_ids=message_ids,
            first_turn=first_turn,
            last_turn=last_turn,
        )

        estimated_summary_tokens = int(tokens * self._target_token_ratio)
        estimated_freed = tokens - estimated_summary_tokens

        return CompactionProposal(
            strategy=self.name,
            span=span,
            estimated_tokens_freed=estimated_freed,
            reason=f"Summarize turns {first_turn}-{last_turn} ({len(message_ids)} messages, {tokens} tokens)",
            priority=first_turn,  # Earlier spans have higher priority
            metadata={
                "original_tokens": tokens,
                "estimated_summary_tokens": estimated_summary_tokens,
                "message_count": len(message_ids),
            },
        )

    async def execute(
        self,
        proposal: CompactionProposal,
        thread: AgentThread,
        tokenizer: ProviderAwareTokenizer,
    ) -> SummarizationRecord:
        """Execute the summarization."""
        if thread.message_store is None:
            raise ValueError("Thread has no message store")

        messages = await thread.message_store.list_messages()
        span_messages = [msg for msg in messages if msg.message_id in proposal.span.message_ids]

        # Call summarizer
        summary = await self._summarizer.summarize(
            span_messages,
            target_token_ratio=self._target_token_ratio,
        )

        # Count summary tokens
        summary_tokens = tokenizer.count_tokens(summary.render_as_message())

        return SummarizationRecord(
            span=proposal.span,
            summary=summary,
            summary_token_count=summary_tokens,
        )


class ExternalizeStrategy(CompactionStrategy):
    """Externalize strategy - write large content to artifact store.

    For content that can't be cleared (NON_REPLAYABLE) but is too large
    to keep in context. Stores full content and keeps pointer + summary.
    """

    def __init__(
        self,
        artifact_store: ArtifactStore,
        summarizer: Summarizer,
        *,
        externalize_threshold_tokens: int = 1000,
        preserve_recent_turns: int = 3,
        default_sensitivity: str = "internal",
        default_ttl_seconds: int | None = None,
    ):
        """Initialize the externalize strategy.

        Args:
            artifact_store: Where to store externalized content.
            summarizer: For generating summaries of externalized content.
            externalize_threshold_tokens: Minimum tokens before externalizing.
            preserve_recent_turns: Don't externalize recent turns.
            default_sensitivity: Default sensitivity level for artifacts.
            default_ttl_seconds: Default TTL for artifacts.
        """
        self._artifact_store = artifact_store
        self._summarizer = summarizer
        self._externalize_threshold_tokens = externalize_threshold_tokens
        self._preserve_recent_turns = preserve_recent_turns
        self._default_sensitivity = default_sensitivity
        self._default_ttl_seconds = default_ttl_seconds

    @property
    def name(self) -> str:
        return "externalize"

    @property
    def aggressiveness(self) -> int:
        return 2  # Less destructive than summarize — preserves full content in store

    async def analyze(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        turn_context: TurnContext | None = None,
    ) -> list[CompactionProposal]:
        """Find content suitable for externalization."""
        proposals: list[CompactionProposal] = []

        # Skip if rehydration happened this turn
        if turn_context is not None and turn_context.should_skip_aggressive_compaction():
            logger.debug("Skipping externalization due to rehydration this turn")
            return proposals

        if thread.message_store is None:
            return proposals

        messages = await thread.message_store.list_messages()
        if not messages:
            return proposals

        # Use message-position-based recency (same as ClearStrategy)
        preserve_tail = self._preserve_recent_turns * 4
        clearable_end = max(0, len(messages) - preserve_tail)

        for i, msg in enumerate(messages):
            if msg.message_id is None:
                continue

            # Skip if already compacted
            if current_plan is not None:
                from ._types import CompactionAction

                action, _ = current_plan.get_action(msg.message_id)
                if action != CompactionAction.INCLUDE:
                    continue

            # Check token count
            token_count = _count_message_tokens(msg, tokenizer)
            if token_count < self._externalize_threshold_tokens:
                continue

            # Check recency — preserve recent messages by position
            if i >= clearable_end:
                continue

            # Check if this is NON_REPLAYABLE tool result (priority) or just large content
            is_non_replayable = False
            if msg.role.value == "tool":
                envelope_data = msg.additional_properties.get("tool_result_envelope")
                if envelope_data:
                    envelope = ToolResultEnvelope.from_dict(envelope_data)
                    durability = envelope.get_effective_durability()
                    is_non_replayable = durability == ToolDurability.NON_REPLAYABLE

            msg_turn = len([m for m in messages[:i] if m.role.value == "user"])

            span = SpanReference(
                message_ids=[msg.message_id],
                first_turn=msg_turn,
                last_turn=msg_turn,
            )

            # Estimate summary tokens (rough)
            estimated_summary_tokens = min(200, token_count // 5)

            content_type = "NON_REPLAYABLE" if is_non_replayable else "large"
            proposals.append(
                CompactionProposal(
                    strategy=self.name,
                    span=span,
                    estimated_tokens_freed=token_count - estimated_summary_tokens - 50,  # ~50 tokens
                    reason=f"Externalize {content_type} content ({token_count} tokens)",
                    priority=0 if is_non_replayable else 1,  # NON_REPLAYABLE has highest priority
                    metadata={
                        "original_tokens": token_count,
                        "is_non_replayable": is_non_replayable,
                    },
                ),
            )

        return proposals

    async def execute(
        self,
        proposal: CompactionProposal,
        thread: AgentThread,
        tokenizer: ProviderAwareTokenizer,
    ) -> ExternalizationRecord:
        """Execute the externalization."""
        if thread.message_store is None:
            raise ValueError("Thread has no message store")

        messages = await thread.message_store.list_messages()
        span_messages = [msg for msg in messages if msg.message_id in proposal.span.message_ids]

        if not span_messages:
            raise ValueError(f"No messages found for span {proposal.span.message_ids}")

        # Combine content for storage
        content = "\n\n".join(msg.text for msg in span_messages)

        # Create metadata
        from ._store import ArtifactMetadata

        metadata = ArtifactMetadata(
            thread_id=str(uuid.uuid4()),  # Should be actual thread ID
            sensitivity=self._default_sensitivity,
            created_at=datetime.now(timezone.utc).isoformat(),
            ttl_seconds=self._default_ttl_seconds,
        )

        # Store content
        artifact_id = await self._artifact_store.store(content, metadata)

        # Generate summary
        summary = await self._summarizer.summarize(
            span_messages,
            target_token_ratio=0.1,  # Very compressed for externalization
        )

        # Add artifact reference to summary
        summary.artifacts.append(
            ArtifactReference(
                artifact_id=artifact_id,
                description=f"Content from turns {proposal.span.first_turn}-{proposal.span.last_turn}",
                rehydrate_hint="Read if you need the full content",
            ),
        )

        return ExternalizationRecord(
            span=proposal.span,
            artifact_id=artifact_id,
            summary=summary,
            rehydrate_hint="Read artifact if you need the full content",
        )


class DropStrategy(CompactionStrategy):
    """Drop strategy - remove content entirely.

    This is the most aggressive strategy and should only be used as a
    last resort when other strategies can't free enough tokens.

    Only drops EPHEMERAL content that has been cleared.
    """

    def __init__(
        self,
        *,
        preserve_recent_turns: int = 2,
    ):
        """Initialize the drop strategy.

        Args:
            preserve_recent_turns: Don't drop content from recent turns.
        """
        self._preserve_recent_turns = preserve_recent_turns

    @property
    def name(self) -> str:
        return "drop"

    @property
    def aggressiveness(self) -> int:
        return 4  # Most aggressive

    async def analyze(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        turn_context: TurnContext | None = None,
    ) -> list[CompactionProposal]:
        """Find content that can be dropped."""
        proposals: list[CompactionProposal] = []

        # Skip if rehydration happened this turn
        if turn_context is not None and turn_context.should_skip_aggressive_compaction():
            logger.debug("Skipping drop due to rehydration this turn")
            return proposals

        if thread.message_store is None:
            return proposals

        # Only drop already-cleared EPHEMERAL content
        if current_plan is None:
            return proposals

        messages = await thread.message_store.list_messages()
        current_turn = len([m for m in messages if m.role.value == "user"])

        for clear_record in current_plan.clearings:
            span = clear_record.span

            # Check recency
            if current_turn - span.last_turn < self._preserve_recent_turns:
                continue

            # Only drop if it was EPHEMERAL
            # Check preserved_fields for durability hint
            durability = clear_record.preserved_fields.get("durability", "anchoring")
            if durability != "ephemeral":
                continue

            # Estimate tokens (cleared content is small, ~20 tokens)
            estimated_freed = 20

            proposals.append(
                CompactionProposal(
                    strategy=self.name,
                    span=span,
                    estimated_tokens_freed=estimated_freed,
                    reason=f"Drop cleared ephemeral content from turns {span.first_turn}-{span.last_turn}",
                    priority=span.first_turn,  # Older first
                ),
            )

        return proposals

    async def execute(
        self,
        proposal: CompactionProposal,
        thread: AgentThread,
        tokenizer: ProviderAwareTokenizer,
    ) -> DropRecord:
        """Execute the drop operation."""
        return DropRecord(
            span=proposal.span,
            reason=proposal.reason,
        )


@dataclass
class CompactionResult:
    """Result of running compaction.

    Attributes:
        plan: The updated compaction plan.
        tokens_freed: Total tokens freed.
        proposals_applied: Number of proposals that were applied.
        proposals_generated: Total proposals generated.
    """

    plan: CompactionPlan
    tokens_freed: int
    proposals_applied: int
    proposals_generated: int

    def to_dict(self) -> dict[str, Any]:
        """Serialize to dictionary."""
        return {
            "plan": self.plan.to_dict(),
            "tokens_freed": self.tokens_freed,
            "proposals_applied": self.proposals_applied,
            "proposals_generated": self.proposals_generated,
        }


class CompactionCoordinator:
    """Coordinates compaction strategies.

    Applies strategies in order of aggressiveness until token budget
    is met or all strategies are exhausted.
    """

    def __init__(
        self,
        strategies: list[CompactionStrategy],
        *,
        max_proposals_per_run: int = 10,
    ):
        """Initialize the coordinator.

        Args:
            strategies: List of strategies to use.
            max_proposals_per_run: Maximum proposals to apply per run.
        """
        # Sort by aggressiveness
        self._strategies = sorted(strategies, key=lambda s: s.aggressiveness)
        self._max_proposals_per_run = max_proposals_per_run

    async def compact(
        self,
        thread: AgentThread,
        current_plan: CompactionPlan | None,
        budget: TokenBudget,
        tokenizer: ProviderAwareTokenizer,
        *,
        tokens_to_free: int = 0,
        turn_context: TurnContext | None = None,
    ) -> CompactionResult:
        """Run compaction to free tokens.

        Args:
            thread: The agent thread to compact.
            current_plan: Existing compaction plan to build on.
            budget: Token budget constraints.
            tokenizer: Tokenizer for counting.
            tokens_to_free: Target tokens to free.
            turn_context: Turn context for loop breaking.

        Returns:
            CompactionResult with updated plan.
        """
        # Start with current plan or empty
        if current_plan is None:  # noqa: SIM108
            plan = CompactionPlan.create_empty(
                thread_id=str(uuid.uuid4()),  # Should be actual thread ID
            )
        else:
            plan = current_plan

        total_tokens_freed = 0
        proposals_applied = 0
        proposals_generated = 0

        # Apply strategies in order
        for strategy in self._strategies:
            if total_tokens_freed >= tokens_to_free:
                break

            logger.debug("Running %s strategy", strategy.name)

            # Analyze
            proposals = await strategy.analyze(
                thread,
                plan,
                budget,
                tokenizer,
                turn_context,
            )
            proposals_generated += len(proposals)

            if not proposals:
                continue

            # Sort by priority
            proposals.sort(key=lambda p: p.priority)

            # Apply proposals
            for proposal in proposals:
                if proposals_applied >= self._max_proposals_per_run:
                    break

                if total_tokens_freed >= tokens_to_free:
                    break

                try:
                    record = await strategy.execute(proposal, thread, tokenizer)

                    # Add record to plan
                    if isinstance(record, ClearRecord):
                        plan.clearings.append(record)
                    elif isinstance(record, SummarizationRecord):
                        plan.summarizations.append(record)
                    elif isinstance(record, ExternalizationRecord):
                        plan.externalizations.append(record)
                    elif isinstance(record, DropRecord):
                        plan.drops.append(record)

                    total_tokens_freed += proposal.estimated_tokens_freed
                    proposals_applied += 1

                    logger.debug(
                        "Applied %s proposal: %s (freed ~%d tokens)",
                        strategy.name,
                        proposal.reason,
                        proposal.estimated_tokens_freed,
                    )

                except Exception as e:
                    logger.warning(
                        "Failed to execute %s proposal: %s",
                        strategy.name,
                        e,
                    )

        # Rebuild action map using public method
        plan.rebuild_action_map()

        # Update token counts
        plan.compacted_token_count = plan.original_token_count - total_tokens_freed

        return CompactionResult(
            plan=plan,
            tokens_freed=total_tokens_freed,
            proposals_applied=proposals_applied,
            proposals_generated=proposals_generated,
        )
